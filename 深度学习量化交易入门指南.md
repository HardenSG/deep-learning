# æ·±åº¦å­¦ä¹ é‡åŒ–äº¤æ˜“å…¥é—¨æŒ‡å—

> å†™ç»™å‰ç«¯å¼€å‘è€…çš„æ·±åº¦å­¦ä¹ è‚¡ç¥¨é¢„æµ‹å®Œå…¨æŒ‡å—

## ğŸ“š ç›®å½•

1. [åŸºç¡€æ¦‚å¿µ](#åŸºç¡€æ¦‚å¿µ)
2. [æ•°æ®å¤„ç†æµç¨‹](#æ•°æ®å¤„ç†æµç¨‹)
3. [æŠ€æœ¯æŒ‡æ ‡è¯¦è§£](#æŠ€æœ¯æŒ‡æ ‡è¯¦è§£)
4. [æ·±åº¦å­¦ä¹ åŸç†](#æ·±åº¦å­¦ä¹ åŸç†)
5. [LSTMæ¨¡å‹è¯¦è§£](#lstmæ¨¡å‹è¯¦è§£)
6. [è®­ç»ƒè¿‡ç¨‹è¯¦è§£](#è®­ç»ƒè¿‡ç¨‹è¯¦è§£)
7. [ä»£ç é€»è¾‘è§£æ](#ä»£ç é€»è¾‘è§£æ)
8. [å®æˆ˜æ¡ˆä¾‹](#å®æˆ˜æ¡ˆä¾‹)

---

## åŸºç¡€æ¦‚å¿µ

### ä»€ä¹ˆæ˜¯é‡åŒ–äº¤æ˜“ï¼Ÿ

**ç®€å•ç†è§£**ï¼šç”¨ç¨‹åºä»£æ›¿äººå·¥åšè‚¡ç¥¨ä¹°å–å†³ç­–ã€‚

```
ä¼ ç»Ÿäº¤æ˜“ï¼šçœ‹Kçº¿å›¾ â†’ äººå·¥åˆ¤æ–­ â†’ ä¹°å…¥/å–å‡º
é‡åŒ–äº¤æ˜“ï¼šæ”¶é›†æ•°æ® â†’ æ¨¡å‹åˆ†æ â†’ è‡ªåŠ¨å†³ç­–
```

**ç±»æ¯”å‰ç«¯**ï¼š
- ä¼ ç»Ÿäº¤æ˜“ = æ‰‹åŠ¨æ“ä½œDOM
- é‡åŒ–äº¤æ˜“ = ç”¨React/Vueè‡ªåŠ¨åŒ–æ¸²æŸ“

### ä»€ä¹ˆæ˜¯æ·±åº¦å­¦ä¹ ï¼Ÿ

**æ ¸å¿ƒæ€æƒ³**ï¼šè®©è®¡ç®—æœºé€šè¿‡å¤§é‡æ•°æ®è‡ªå·±å­¦ä¹ è§„å¾‹ã€‚

```javascript
// ç±»æ¯”ï¼šå‰ç«¯çš„æœºå™¨å­¦ä¹ 
// ä¼ ç»Ÿæ–¹å¼ï¼šå†™æ­»è§„åˆ™
function shouldShowAd(user) {
  if (user.age > 18 && user.clicks > 10) {
    return true;
  }
  return false;
}

// æ·±åº¦å­¦ä¹ æ–¹å¼ï¼šè®©æ¨¡å‹è‡ªå·±å­¦ä¹ è§„å¾‹
const model = trainModel(userData);
const shouldShow = model.predict(user); // æ¨¡å‹è‡ªå·±åˆ¤æ–­
```

### ä¸ºä»€ä¹ˆç”¨LSTMï¼Ÿ

**é—®é¢˜**ï¼šè‚¡ç¥¨ä»·æ ¼æ˜¯æ—¶é—´åºåˆ—æ•°æ®ï¼Œä»Šå¤©çš„ä»·æ ¼å—æ˜¨å¤©ã€å‰å¤©...å½±å“ã€‚

**LSTMçš„ä¼˜åŠ¿**ï¼šèƒ½"è®°ä½"å†å²ä¿¡æ¯ã€‚

```
æ™®é€šç¥ç»ç½‘ç»œï¼šåªçœ‹ä»Šå¤©çš„æ•°æ®
LSTMï¼šèƒ½è®°ä½è¿‡å»60å¤©çš„æ•°æ®ï¼Œç»¼åˆåˆ¤æ–­
```

**ç±»æ¯”å‰ç«¯**ï¼š
```javascript
// æ™®é€šå‡½æ•°ï¼šæ— çŠ¶æ€
function add(a, b) {
  return a + b;
}

// LSTMï¼šæœ‰è®°å¿†ï¼ˆç±»ä¼¼Reactçš„useStateï¼‰
function LSTMCell() {
  const [memory, setMemory] = useState([]);
  
  function process(newData) {
    // ç»“åˆå†å²è®°å¿†å’Œæ–°æ•°æ®
    const result = analyze([...memory, newData]);
    setMemory([...memory, newData]); // æ›´æ–°è®°å¿†
    return result;
  }
}
```

---

## æ•°æ®å¤„ç†æµç¨‹

### å®Œæ•´æµç¨‹å›¾

```
åŸå§‹æ•°æ® â†’ æ•°æ®æ¸…æ´— â†’ ç‰¹å¾å·¥ç¨‹ â†’ æ•°æ®æ ‡å‡†åŒ– â†’ è®­ç»ƒæ¨¡å‹ â†’ é¢„æµ‹
```

### 1. åŸå§‹æ•°æ®

ä»akshareè·å–çš„è‚¡ç¥¨æ•°æ®ï¼š

```python
# åŸå§‹æ•°æ®ç¤ºä¾‹
{
  "æ—¥æœŸ": "2024-01-05",
  "å¼€ç›˜": 10.50,
  "æ”¶ç›˜": 10.80,
  "æœ€é«˜": 11.00,
  "æœ€ä½": 10.40,
  "æˆäº¤é‡": 1000000,
  "æˆäº¤é¢": 10800000
}
```

**ç±»æ¯”å‰ç«¯**ï¼šå°±åƒä»APIè·å–çš„åŸå§‹JSONæ•°æ®ã€‚

### 2. æ•°æ®æ¸…æ´—

```python
# å¤„ç†ç¼ºå¤±å€¼ã€å¼‚å¸¸å€¼
df = df.dropna()  # åˆ é™¤ç©ºå€¼
df = df[df['volume'] > 0]  # åˆ é™¤æˆäº¤é‡ä¸º0çš„æ•°æ®
```

**ç±»æ¯”å‰ç«¯**ï¼š
```javascript
// è¿‡æ»¤æ— æ•ˆæ•°æ®
const validData = rawData.filter(item => 
  item.price > 0 && item.volume > 0
);
```

### 3. ç‰¹å¾å·¥ç¨‹ï¼ˆæœ€é‡è¦ï¼ï¼‰

**ç›®çš„**ï¼šä»åŸå§‹æ•°æ®ä¸­æå–æœ‰ç”¨çš„ç‰¹å¾ã€‚

#### ç¤ºä¾‹ï¼šè®¡ç®—ç§»åŠ¨å¹³å‡çº¿ï¼ˆMAï¼‰

```python
# 5æ—¥ç§»åŠ¨å¹³å‡çº¿
df['ma_5'] = df['close'].rolling(window=5).mean()
```

**åŸç†**ï¼š
```
å‡è®¾æœ€è¿‘5å¤©æ”¶ç›˜ä»·ï¼š[10, 11, 10.5, 11.5, 12]
MA5 = (10 + 11 + 10.5 + 11.5 + 12) / 5 = 11
```

**æ„ä¹‰**ï¼šå¹³æ»‘ä»·æ ¼æ³¢åŠ¨ï¼Œçœ‹æ¸…è¶‹åŠ¿ã€‚

**ç±»æ¯”å‰ç«¯**ï¼š
```javascript
// è®¡ç®—æœ€è¿‘5æ¬¡ç‚¹å‡»çš„å¹³å‡é—´éš”
function calculateAvgInterval(clicks) {
  const recent5 = clicks.slice(-5);
  const intervals = recent5.map((click, i) => 
    i > 0 ? click.time - recent5[i-1].time : 0
  );
  return intervals.reduce((a, b) => a + b) / 5;
}
```

### 4. æ•°æ®æ ‡å‡†åŒ–

**é—®é¢˜**ï¼šä¸åŒç‰¹å¾çš„æ•°å€¼èŒƒå›´å·®å¼‚å¤§ã€‚

```
ä»·æ ¼ï¼š10-100å…ƒ
æˆäº¤é‡ï¼š1000000-10000000è‚¡
```

**è§£å†³**ï¼šå½’ä¸€åŒ–åˆ°0-1ä¹‹é—´ã€‚

```python
from sklearn.preprocessing import MinMaxScaler

scaler = MinMaxScaler()
normalized_data = scaler.fit_transform(data)
```

**åŸç†**ï¼š
```
å½’ä¸€åŒ–å…¬å¼ï¼š(x - min) / (max - min)

ä¾‹å¦‚ï¼šä»·æ ¼èŒƒå›´ [10, 100]
ä»·æ ¼ 50 å½’ä¸€åŒ–å = (50 - 10) / (100 - 10) = 0.44
```

**ç±»æ¯”å‰ç«¯**ï¼š
```javascript
// å°†ä¸åŒèŒƒå›´çš„æ•°æ®ç»Ÿä¸€åˆ°0-1
function normalize(value, min, max) {
  return (value - min) / (max - min);
}

// ä¾‹å¦‚ï¼šå°†å¹´é¾„(0-100)å’Œæ”¶å…¥(0-1000000)ç»Ÿä¸€
const normalizedAge = normalize(25, 0, 100);      // 0.25
const normalizedIncome = normalize(50000, 0, 1000000); // 0.05
```

---

## æŠ€æœ¯æŒ‡æ ‡è¯¦è§£

### 1. ç§»åŠ¨å¹³å‡çº¿ï¼ˆMAï¼‰

**ä½œç”¨**ï¼šåˆ¤æ–­è¶‹åŠ¿æ–¹å‘ã€‚

```python
# è®¡ç®—5æ—¥ã€10æ—¥ã€20æ—¥å‡çº¿
df['ma_5'] = df['close'].rolling(5).mean()
df['ma_10'] = df['close'].rolling(10).mean()
df['ma_20'] = df['close'].rolling(20).mean()
```

**ä½¿ç”¨æ–¹æ³•**ï¼š
- çŸ­æœŸå‡çº¿ä¸Šç©¿é•¿æœŸå‡çº¿ â†’ ä¹°å…¥ä¿¡å·ï¼ˆé‡‘å‰ï¼‰
- çŸ­æœŸå‡çº¿ä¸‹ç©¿é•¿æœŸå‡çº¿ â†’ å–å‡ºä¿¡å·ï¼ˆæ­»å‰ï¼‰

**å¯è§†åŒ–ç†è§£**ï¼š
```
ä»·æ ¼ï¼š  â—â”€â—â”€â—â”€â—â”€â—â”€â—â”€â—â”€â—
MA5ï¼š   â”€â”€â”€â”€â”€â—â”€â”€â”€â”€â”€â—â”€â”€â”€â”€â”€
MA10ï¼š  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â—â”€â”€â”€â”€â”€
```

### 2. MACDï¼ˆæŒ‡æ•°å¹³æ»‘å¼‚åŒç§»åŠ¨å¹³å‡çº¿ï¼‰

**ä½œç”¨**ï¼šåˆ¤æ–­ä¹°å–æ—¶æœºã€‚

```python
# è®¡ç®—MACD
ema_12 = df['close'].ewm(span=12).mean()  # 12æ—¥æŒ‡æ•°ç§»åŠ¨å¹³å‡
ema_26 = df['close'].ewm(span=26).mean()  # 26æ—¥æŒ‡æ•°ç§»åŠ¨å¹³å‡

df['macd'] = ema_12 - ema_26              # MACDçº¿
df['signal'] = df['macd'].ewm(span=9).mean()  # ä¿¡å·çº¿
df['hist'] = df['macd'] - df['signal']   # æŸ±çŠ¶å›¾
```

**è§£è¯»**ï¼š
- MACD > 0ï¼šå¤šå¤´å¸‚åœº
- MACD < 0ï¼šç©ºå¤´å¸‚åœº
- MACDä¸Šç©¿ä¿¡å·çº¿ï¼šä¹°å…¥
- MACDä¸‹ç©¿ä¿¡å·çº¿ï¼šå–å‡º

### 3. RSIï¼ˆç›¸å¯¹å¼ºå¼±æŒ‡æ ‡ï¼‰

**ä½œç”¨**ï¼šåˆ¤æ–­è¶…ä¹°è¶…å–ã€‚

```python
# è®¡ç®—RSI
delta = df['close'].diff()
gain = delta.where(delta > 0, 0).rolling(14).mean()
loss = -delta.where(delta < 0, 0).rolling(14).mean()

rs = gain / loss
df['rsi'] = 100 - (100 / (1 + rs))
```

**è§£è¯»**ï¼š
- RSI > 70ï¼šè¶…ä¹°ï¼Œå¯èƒ½ä¸‹è·Œ
- RSI < 30ï¼šè¶…å–ï¼Œå¯èƒ½ä¸Šæ¶¨
- RSI = 50ï¼šä¸­æ€§

**ç±»æ¯”å‰ç«¯**ï¼š
```javascript
// ç±»ä¼¼äºè®¡ç®—ç”¨æˆ·æ´»è·ƒåº¦
function calculateActivityScore(actions) {
  const positiveActions = actions.filter(a => a.type === 'positive');
  const negativeActions = actions.filter(a => a.type === 'negative');
  
  const score = (positiveActions.length / negativeActions.length) * 100;
  
  if (score > 70) return 'éå¸¸æ´»è·ƒ';
  if (score < 30) return 'ä¸æ´»è·ƒ';
  return 'æ­£å¸¸';
}
```

### 4. å¸ƒæ—å¸¦ï¼ˆBollinger Bandsï¼‰

**ä½œç”¨**ï¼šåˆ¤æ–­ä»·æ ¼æ³¢åŠ¨èŒƒå›´ã€‚

```python
# è®¡ç®—å¸ƒæ—å¸¦
df['bb_middle'] = df['close'].rolling(20).mean()  # ä¸­è½¨
std = df['close'].rolling(20).std()               # æ ‡å‡†å·®
df['bb_upper'] = df['bb_middle'] + 2 * std       # ä¸Šè½¨
df['bb_lower'] = df['bb_middle'] - 2 * std       # ä¸‹è½¨
```

**è§£è¯»**ï¼š
- ä»·æ ¼è§¦åŠä¸Šè½¨ï¼šå¯èƒ½å›è½
- ä»·æ ¼è§¦åŠä¸‹è½¨ï¼šå¯èƒ½åå¼¹
- å¸ƒæ—å¸¦æ”¶çª„ï¼šå³å°†å¤§å¹…æ³¢åŠ¨

**å¯è§†åŒ–**ï¼š\nä¸Šè½¨ï¼š  â”€â”€n```â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
ä»·æ ¼ï¼š    â—â”€â—â”€â—â”€â—â”€â—â”€â—
ä¸­è½¨ï¼š  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
ä¸‹è½¨ï¼š  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
```

---

## æ·±åº¦å­¦ä¹ åŸç†

### 1. ç¥ç»ç½‘ç»œåŸºç¡€

**æ ¸å¿ƒæ€æƒ³**ï¼šæ¨¡æ‹Ÿäººè„‘ç¥ç»å…ƒã€‚

```
è¾“å…¥å±‚ â†’ éšè—å±‚ â†’ è¾“å‡ºå±‚
```

**å•ä¸ªç¥ç»å…ƒ**ï¼š
```python
# ç¥ç»å…ƒçš„è®¡ç®—è¿‡ç¨‹
def neuron(inputs, weights, bias):
    # 1. åŠ æƒæ±‚å’Œ
    weighted_sum = sum(x * w for x, w in zip(inputs, weights))
    
    # 2. åŠ ä¸Šåç½®
    result = weighted_sum + bias
    
    # 3. æ¿€æ´»å‡½æ•°ï¼ˆå¼•å…¥éçº¿æ€§ï¼‰
    output = activation(result)
    
    return output
```

**ç±»æ¯”å‰ç«¯**ï¼š
```javascript
// ç±»ä¼¼äºä¸€ä¸ªå¤æ‚çš„if-elseå†³ç­–æ ‘
function makeDecision(features) {
  // æ¯ä¸ªç‰¹å¾æœ‰ä¸åŒçš„æƒé‡
  const score = 
    features.age * 0.3 +
    features.income * 0.5 +
    features.clicks * 0.2;
  
  // æ¿€æ´»å‡½æ•°ï¼šå†³å®šæ˜¯å¦è§¦å‘
  return score > threshold ? 'yes' : 'no';
}
```

### 2. å‰å‘ä¼ æ’­

**è¿‡ç¨‹**ï¼šæ•°æ®ä»è¾“å…¥å±‚æµå‘è¾“å‡ºå±‚ã€‚

```python
# ç®€åŒ–çš„å‰å‘ä¼ æ’­
class SimpleNN:
    def forward(self, x):
        # ç¬¬ä¸€å±‚
        h1 = relu(x @ W1 + b1)
        
        # ç¬¬äºŒå±‚
        h2 = relu(h1 @ W2 + b2)
        
        # è¾“å‡ºå±‚
        output = h2 @ W3 + b3
        
        return output
```

**å¯è§†åŒ–**ï¼š
```
è¾“å…¥: [ä»·æ ¼, æˆäº¤é‡, MA5, ...]
  â†“
éšè—å±‚1: [ç¥ç»å…ƒ1, ç¥ç»å…ƒ2, ...]
  â†“
éšè—å±‚2: [ç¥ç»å…ƒ1, ç¥ç»å…ƒ2, ...]
  â†“
è¾“å‡º: é¢„æµ‹æ”¶ç›Šç‡
```

### 3. åå‘ä¼ æ’­ï¼ˆè®­ç»ƒçš„æ ¸å¿ƒï¼‰

**ç›®çš„**ï¼šè°ƒæ•´æƒé‡ï¼Œè®©é¢„æµ‹æ›´å‡†ç¡®ã€‚

```python
# è®­ç»ƒè¿‡ç¨‹
for epoch in range(100):
    # 1. å‰å‘ä¼ æ’­ï¼šå¾—åˆ°é¢„æµ‹å€¼
    prediction = model.forward(X)
    
    # 2. è®¡ç®—æŸå¤±ï¼šé¢„æµ‹å€¼ä¸çœŸå®å€¼çš„å·®è·
    loss = (prediction - y_true) ** 2
    
    # 3. åå‘ä¼ æ’­ï¼šè®¡ç®—æ¢¯åº¦
    gradients = compute_gradients(loss)
    
    # 4. æ›´æ–°æƒé‡ï¼šæœç€å‡å°æŸå¤±çš„æ–¹å‘è°ƒæ•´
    weights = weights - learning_rate * gradients
```

**ç±»æ¯”å‰ç«¯script
// ç±»ä¼¼äºA/Bæµ‹ioè¯•ä¼˜åŒ–
opfuncttton() {
 tttimizeBu**ï¼š
```javan  let buonColor = 'blue';
  let clickRate = 0.1;
  
  for (let i = 0; i < 100; i++) {
    // å°è¯•æ–°é¢œè‰²
    const newColor = adjustColor(buttonColor);
    const newClickRate = testClickRate(newColor);
    
    // å¦‚æœæ•ˆæœæ›´å¥½ï¼Œå°±é‡‡ç”¨æ–°é¢œè‰²
    if (newClickRate > clickRate) {
      buttonColor = newColor;
      clickRate = newClickRate;
    }
  }
  
  return buttonColor;
}
```

### 4. æŸå¤±å‡½æ•°

**ä½œç”¨**ï¼šè¡¡é‡é¢„æµ‹çš„å¥½åã€‚

```python
# å‡æ–¹è¯¯å·®ï¼ˆMSEï¼‰
def mse_loss(predictions, targets):
    return ((predictions - targets) ** 2).mean()

# ä¾‹å­
predictions = [0.05, 0.03, -0.02]  # é¢„æµ‹æ”¶ç›Šç‡
targets = [0.04, 0.05, -0.01]      # å®é™…æ”¶ç›Šç‡

loss = mse_loss(predictions, targets)
# loss = ((0.05-0.04)Â² + (0.03-0.05)Â² + (-0.02-(-0.01))Â²) / 3
# loss = (0.0001 + 0.0004 + 0.0001) / 3 = 0.0002
```

**ç›®æ ‡**ï¼šè®©lossè¶Šå°è¶Šå¥½ã€‚

---

## LSTMæ¨¡å‹è¯¦è§£

### 1. ä¸ºä»€ä¹ˆéœ€è¦LSTMï¼Ÿ

**é—®é¢˜**ï¼šæ™®é€šç¥ç»ç½‘ç»œæ— æ³•å¤„ç†åºåˆ—æ•°æ®ã€‚

```
æ™®é€šNNï¼š
è¾“å…¥ï¼šä»Šå¤©çš„æ•°æ® â†’ è¾“å‡ºï¼šé¢„æµ‹

LSTMï¼š
è¾“å…¥ï¼šè¿‡å»60å¤©çš„æ•°æ® â†’ è¾“å‡ºï¼šé¢„æµ‹
```

### 2. LSTMçš„ç»“æ„

**æ ¸å¿ƒç»„ä»¶**ï¼š

```
1. é—å¿˜é—¨ï¼ˆForget Gateï¼‰ï¼šå†³å®šä¸¢å¼ƒå“ªäº›æ—§ä¿¡æ¯
2. è¾“å…¥é—¨ï¼ˆInput Gateï¼‰ï¼šå†³å®šå­˜å‚¨å“ªäº›æ–°ä¿¡æ¯
3. è¾“å‡ºé—¨ï¼ˆOutput Gateï¼‰ï¼šå†³å®šè¾“å‡ºä»€ä¹ˆä¿¡æ¯
```

**å¯è§†åŒ–**ï¼š
```
        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
æ—§è®°å¿† â†’â”‚  é—å¿˜é—¨     â”‚â†’ æ›´æ–°åçš„è®°å¿†
        â”‚  è¾“å…¥é—¨     â”‚
æ–°æ•°æ® â†’â”‚  è¾“å‡ºé—¨     â”‚â†’ è¾“å‡º
        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### 3. LSTMçš„è®¡ç®—è¿‡ç¨‹

```python
class LSTMCell:
    def forward(self, x, h_prev, c_prev):
        # 1. é—å¿˜é—¨ï¼šå†³å®šé—å¿˜å¤šå°‘æ—§è®°å¿†
        f = sigmoid(W_f @ [h_prev, x] + b_f)
        
        # 2. è¾“å…¥é—¨ï¼šå†³å®šå­˜å‚¨å¤šå°‘æ–°ä¿¡æ¯
        i = sigmoid(W_i @ [h_prev, x] + b_i)
        c_new = tanh(W_c @ [h_prev, x] + b_c)
        
        # 3. æ›´æ–°è®°å¿†
        c = f * c_prev + i * c_new
        
        # 4. è¾“å‡ºé—¨ï¼šå†³å®šè¾“å‡ºä»€ä¹ˆ
        o = sigmoid(W_o @ [h_prev, x] + b_o)
        h = o * tanh(c)
        
        return h, c
```

**ç±»æ¯”å‰ç«¯**ï¼š
```javascript
// LSTMå°±åƒä¸€ä¸ªæ™ºèƒ½çš„çŠ¶æ€ç®¡ç†å™¨
class SmartStateManager {
  constructor() {
    this.memory = [];  // é•¿æœŸè®°å¿†
    this.state = {};   // å½“å‰çŠ¶æ€
  }
  
  update(newData) {
    // 1. å†³å®šé—å¿˜å“ªäº›æ—§æ•°æ®
    this.memory = this.memory.filter(item => 
      this.shouldKeep(item)
    );
    
    // 2. å†³å®šå­˜å‚¨å“ªäº›æ–°æ•°æ®
    if (this.shouldStore(newData)) {
      this.memory.push(newData);
    }
    
    // 3. åŸºäºè®°å¿†å’Œæ–°æ•°æ®ï¼Œæ›´æ–°çŠ¶æ€
    this.state = this.computeState(this.memory, newData);
    
    return this.state;
  }
}
```

### 4. æˆ‘ä»¬çš„LSTMæ¨¡å‹

```python
class LSTMModel(nn.Module):
    def __init__(self, input_size=36, hidden_size=128, num_layers=2):
        super().__init__()
        
        # LSTMå±‚ï¼šå¤„ç†æ—¶é—´åºåˆ—
        self.lstm = nn.LSTM(
            input_size=36,      # 36ä¸ªç‰¹å¾
            hidden_size=128,    # 128ä¸ªéšè—å•å…ƒ
            num_layers=2,       # 2å±‚LSTM
            batch_first=True    # æ‰¹æ¬¡åœ¨ç¬¬ä¸€ç»´
        )
        
        # å…¨è¿æ¥å±‚ï¼šå°†LSTMè¾“å‡ºè½¬æ¢ä¸ºé¢„æµ‹å€¼
        self.fc = nn.Sequential(
            nn.Linear(128, 64),  # 128 â†’ 64
            nn.ReLU(),           # æ¿€æ´»å‡½æ•°
            nn.Dropout(0.2),     # é˜²æ­¢è¿‡æ‹Ÿåˆ
            nn.Linear(64, 32),   # 64 â†’ 32
            nn.ReLU(),
            nn.Dropout(0.2),
            nn.Linear(32, 1)     # 32 â†’ 1ï¼ˆé¢„æµ‹å€¼ï¼‰
        )
    
    def forward(self, x):
        # x shape: (batch_size, 60, 36)
        # 60å¤©çš„å†å²æ•°æ®ï¼Œæ¯å¤©36ä¸ªç‰¹å¾
        
        # LSTMå¤„ç†
        lstm_out, _ = self.lstm(x)
        # lstm_out shape: (batch_size, 60, 128)
        
        # å–æœ€åä¸€å¤©çš„è¾“å‡º
        last_output = lstm_out[:, -1, :]
        # last_output shape: (batch_size, 128)
        
        # å…¨è¿æ¥å±‚é¢„æµ‹
        prediction = self.fc(last_output)
        # prediction shape: (batch_size, 1)
        
        return prediction
```

**æ•°æ®æµåŠ¨**ï¼š
```
è¾“å…¥: (32, 60, 36)  # 32ä¸ªæ ·æœ¬ï¼Œæ¯ä¸ª60å¤©ï¼Œæ¯å¤©36ä¸ªç‰¹å¾
  â†“
LSTM: (32, 60, 128) # æå–æ—¶åºç‰¹å¾
  â†“
å–æœ€åä¸€å¤©: (32, 128)
  â†“
å…¨è¿æ¥å±‚: (32, 64) â†’ (32, 32) â†’ (32, 1)
  â†“
è¾“å‡º: (32, 1)       # 32ä¸ªé¢„æµ‹å€¼
```

---

## è®­ç»ƒè¿‡ç¨‹è¯¦è§£

### 1. æ•°æ®å‡†å¤‡

```python
# 1. åŠ è½½æ•°æ®
df = database.get_stock_daily('000001')
# df: 1456æ¡è®°å½•

# 2. è®¡ç®—æŠ€æœ¯æŒ‡æ ‡
df = calculate_indicators(df)
# æ–°å¢36ä¸ªç‰¹å¾åˆ—

# 3. åˆ›å»ºæ—¶é—´çª—å£
X, y = [], []
window_size = 60

for i in range(len(df) - window_size - 5):
    # è¾“å…¥ï¼šè¿‡å»60å¤©çš„æ•°æ®
    X.append(df[i:i+60])
    
    # è¾“å‡ºï¼šæœªæ¥5å¤©çš„æ”¶ç›Šç‡
    future_price = df['close'][i+60+5]
    current_price = df['close'][i+60]
    y.append((future_price - current_price) / current_price)

# X shape: (1333, 60, 36)
# y shape: (1333,)
```

**å¯è§†åŒ–**ï¼š
```
åŸå§‹æ•°æ®ï¼š1456å¤©
  â†“
æ»‘åŠ¨çª—å£ï¼š
[ç¬¬1-60å¤©] â†’ é¢„æµ‹ç¬¬65å¤©æ”¶ç›Šç‡
[ç¬¬2-61å¤©] â†’ é¢„æµ‹ç¬¬66å¤©æ”¶ç›Šç‡
...
[ç¬¬1333-1392å¤©] â†’ é¢„æµ‹ç¬¬1397å¤©æ”¶ç›Šç‡
  â†“
å¾—åˆ°1333ä¸ªè®­ç»ƒæ ·æœ¬
```

### 2. æ•°æ®é›†åˆ’åˆ†

```python
# åˆ’åˆ†æ¯”ä¾‹
train: 70% = 933ä¸ªæ ·æœ¬
val:   20% = 266ä¸ªæ ·æœ¬
test:  10% = 134ä¸ªæ ·æœ¬

# ä¸ºä»€ä¹ˆè¿™æ ·åˆ’åˆ†ï¼Ÿ
# - è®­ç»ƒé›†ï¼šç”¨æ¥å­¦ä¹ 
# - éªŒè¯é›†ï¼šç”¨æ¥è°ƒå‚
# - æµ‹è¯•é›†ï¼šç”¨æ¥è¯„ä¼°æœ€ç»ˆæ•ˆæœ
```

**ç±»æ¯”å‰ç«¯**ï¼š
```javascript
// ç±»ä¼¼äºå¼€å‘ã€æµ‹è¯•ã€ç”Ÿäº§ç¯å¢ƒ
const data = getAllData();

const trainData = data.slice(0, 0.7 * data.length);  // å¼€å‘
const valData = data.slice(0.7 * data.length, 0.9 * data.length);  // æµ‹è¯•
const testData = data.slice(0.9 * data.length);  // ç”Ÿäº§
```

### 3. è®­ç»ƒå¾ªç¯

```python
for epoch in range(100):  # è®­ç»ƒ100è½®
    # ===== è®­ç»ƒé˜¶æ®µ =====
    model.train()  # è®¾ç½®ä¸ºè®­ç»ƒæ¨¡å¼
    train_loss = 0
    
    for batch_X, batch_y in train_loader:
        # 1. å‰å‘ä¼ æ’­
        predictions = model(batch_X)
        
        # 2. è®¡ç®—æŸå¤±
        loss = criterion(predictions, batch_y)
        
        # 3. åå‘ä¼ æ’­
        optimizer.zero_grad()  # æ¸…ç©ºæ¢¯åº¦
        loss.backward()        # è®¡ç®—æ¢¯åº¦
        
        # 4. æ¢¯åº¦è£å‰ªï¼ˆé˜²æ­¢æ¢¯åº¦çˆ†ç‚¸ï¼‰
        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)
        
        # 5. æ›´æ–°æƒé‡
        optimizer.step()
        
        train_loss += loss.item()
    
    # ===== éªŒè¯é˜¶æ®µ =====
    model.eval()  # è®¾ç½®ä¸ºè¯„ä¼°æ¨¡å¼
    val_loss = 0
    
    with torch.no_grad():  # ä¸è®¡ç®—æ¢¯åº¦
        for batch_X, batch_y in val_loader:
            predictions = model(batch_X)
            loss = criterion(predictions, batch_y)
            val_loss += loss.item()
    
    # ===== ä¿å­˜æœ€ä½³æ¨¡å‹ =====
    if val_loss < best_val_loss:
        best_val_loss = val_loss
        torch.save(model.state_dict(), 'best_model.pth')
        patience_counter = 0
    else:
        patience_counter += 1
    
    # ===== Early Stopping =====
    if patience_counter >= 10:
        print(f'Early stopping at epoch {epoch}')
        break
```

**è®­ç»ƒè¿‡ç¨‹å¯è§†åŒ–**ï¼š
```
Epoch 1:  Train Loss: 0.004760, Val Loss: 0.001660 âœ“ ä¿å­˜
Epoch 2:  Train Loss: 0.003221, Val Loss: 0.001389 âœ“ ä¿å­˜
Epoch 3:  Train Loss: 0.002979, Val Loss: 0.001342 âœ“ ä¿å­˜
...
Epoch 10: Train Loss: 0.003303, Val Loss: 0.001311 âœ“ ä¿å­˜
Epoch 11: Train Loss: 0.002847, Val Loss: 0.001311 (æ²¡æœ‰æ”¹è¿›)
...
Epoch 22: Train Loss: 0.002702, Val Loss: 0.001342 (è¿ç»­10è½®æ²¡æ”¹è¿›)
â†’ Early Stoppingï¼
```

### 4. å…³é”®æ¦‚å¿µè§£é‡Š

#### Batch Sizeï¼ˆæ‰¹æ¬¡å¤§å°ï¼‰

```python
batch_size = 32

# ä¸ä½¿ç”¨batchï¼šæ¯æ¬¡ç”¨1ä¸ªæ ·æœ¬æ›´æ–°æƒé‡ï¼ˆå¤ªæ…¢ï¼‰
# ä½¿ç”¨batchï¼šæ¯æ¬¡ç”¨32ä¸ªæ ·æœ¬æ›´æ–°æƒé‡ï¼ˆå¿«ä¸”ç¨³å®šï¼‰
```

**ç±»æ¯”å‰ç«¯**ï¼š
```javascript
// ä¸ä½¿ç”¨batchï¼šæ¯æ¬¡å¤„ç†1ä¸ªè¯·æ±‚
requests.forEach(req => {
  processRequest(req);
  updateUI();  // é¢‘ç¹æ›´æ–°ï¼Œæ€§èƒ½å·®
});

// ä½¿ç”¨batchï¼šæ¯æ¬¡å¤„ç†32ä¸ªè¯·æ±‚
for (let i = 0; i < requests.length; i += 32) {
  const batch = requests.slice(i, i + 32);
  processBatch(batch);
  updateUI();  // æ‰¹é‡æ›´æ–°ï¼Œæ€§èƒ½å¥½
}
```

#### Learning Rateï¼ˆå­¦ä¹ ç‡ï¼‰

```python
learning_rate = 0.001

# å­¦ä¹ ç‡å¤ªå¤§ï¼šå¯èƒ½é”™è¿‡æœ€ä¼˜è§£
# å­¦ä¹ ç‡å¤ªå°ï¼šè®­ç»ƒå¤ªæ…¢
```

**å¯è§†åŒ–**ï¼š
```
æŸå¤±å‡½æ•°æ›²çº¿ï¼š
    â•±â•²
   â•±  â•²
  â•±    â•²___æœ€ä¼˜ç‚¹
 â•±

å­¦ä¹ ç‡å¤ªå¤§ï¼š
  â—â”€â”€â”€â”€è·³è¿‡â”€â”€â”€â”€â—  (æ­¥å­å¤ªå¤§ï¼Œè·³è¿‡æœ€ä¼˜ç‚¹)

å­¦ä¹ ç‡åˆé€‚ï¼š
  â—â†’â—â†’â—â†’â—â†’â—  (é€æ­¥æ¥è¿‘æœ€ä¼˜ç‚¹)

å­¦ä¹ ç‡å¤ªå°ï¼š
  â—.â—.â—.â—.â—  (æ­¥å­å¤ªå°ï¼Œè®­ç»ƒå¤ªæ…¢)
```

#### Dropoutï¼ˆéšæœºå¤±æ´»ï¼‰

```python
nn.Dropout(0.2)  # éšæœºä¸¢å¼ƒ20%çš„ç¥ç»å…ƒ

# ä½œç”¨ï¼šé˜²æ­¢è¿‡æ‹Ÿåˆ
# åŸç†ï¼šå¼ºåˆ¶æ¨¡å‹ä¸ä¾èµ–æŸå‡ ä¸ªç¥ç»å…ƒ
```

**ç±»æ¯”å‰ç«¯**ï¼š
```javascript
// ç±»ä¼¼äºä»£ç çš„å®¹é”™è®¾è®¡
function robustPredict(features) {
  // éšæœºå¿½ç•¥20%çš„ç‰¹å¾
  const activeFeatures = features.filter(() => 
    Math.random() > 0.2
  );
  
  // å¼ºåˆ¶æ¨¡å‹å­¦ä¼šç”¨ä¸åŒçš„ç‰¹å¾ç»„åˆ
  return predict(activeFeatures);
}
```

---

## ä»£ç é€»è¾‘è§£æ

### å®Œæ•´è®­ç»ƒæµç¨‹ä»£ç 

```python
# ===== 1. åˆå§‹åŒ– =====
import torch
from src.utils.database import Database
from src.data_collector.stock_data import StockDataCollector
from src.feature_engineering.feature_builder import FeatureBuilder
from src.models.lstm_model import LSTMModel
from src.models.trainer import ModelTrainer

# åŠ è½½é…ç½®
config = load_config()

# ===== 2. æ•°æ®é‡‡é›† =====
db = Database()
collector = StockDataColldb)

# ector(é‡‡é›†è‚¡ç¥¨æ•°æ®
collector.collect_stock_data(
    stock_code='000001',
    start_date='2020-01-01'
)

# ===== 3. åŠ è½½æ•°æ® =====
df = db.get_stock_daily('000001')
print(f"æ•°æ®é‡: {len(df)} æ¡")

# ===== 4. ç‰¹å¾å·¥ç¨‹ =====
feature_builder = FeatureBuilder(config.features)

# è®¡ç®—æŠ€æœ¯æŒ‡æ ‡å¹¶å‡†å¤‡è®­ç»ƒæ•°æ®
X, y, feature_columns = feature_builder.prepare_training_data(
    df,
    target_column='close',
    prediction_horizon=5  # é¢„æµ‹æœªæ¥5å¤©
)

print(f"ç‰¹å¾æ•°é‡: {len(feature_columns)}")
print(f"æ ·æœ¬æ•°é‡: {len(X)}")

# ===== 5. åˆ’åˆ†æ•°æ®é›† =====
X_train, y_train, X_val, y_val, X_test, y_test = \
    feature_builder.split_data(X, y, train_ratio=0.7, val_ratio=0.2)

# ===== 6. åˆ›å»ºæ¨¡å‹ =====
model = LSTMModel(
    input_size=X.shape[2],  # ç‰¹å¾æ•°é‡
    hidden_size=128,
    num_layers=2,
    dropout=0.2
)

print(f"æ¨¡å‹å‚æ•°: {model.get_model_info()}")

# ===== 7. åˆ›å»ºè®­ç»ƒå™¨ =====
trainer = ModelTrainer(
    model,
    device='cpu',  # æˆ– 'cuda'
    learning_rate=0.001
)

# ===== 8. è®­ç»ƒæ¨¡å‹ =====
history = trainer.train(
    X_train, y_train,
    X_val, y_val,
    epochs=100,
    batch_size=32,
    early_stopping_patience=10,
    save_path='data/models/000001_model.pth'
)

# ===== 9. è¯„ä¼°æ¨¡å‹ =====
metrics = trainer.evaluate(X_test, y_test)
print(f"æµ‹è¯•é›†è¯„ä¼°: {metrics}")

# ===== 10. ä¿å­˜Scal==
feature_builder.save_scaler(1_scal'data/er.pkl')

models/00000print("è®­ç»ƒå®Œ")
```er ===æˆï¼

### å…³é”®ç±»è¯¦è§£

#### 1. FeatureBuilderï¼ˆç‰¹å¾æ„å»ºå™¨ï¼‰

```python
class FeatureBuilder:
    def __init__(self, config):
        self.window_size = 60  # æ—¶é—´çª—å£
        self.scaler = None     # æ•°æ®æ ‡å‡†åŒ–å™¨
    
    def build_features(self, df):
        """è®¡ç®—æ‰€æœ‰æŠ€æœ¯æŒ‡æ ‡"""
        # è®¡ç®—MA
        df['ma_5'] = df['close'].rolling(5).mean()
        df['ma_10'] = df['close'].rolling(10).mean()
        
        # è®¡ç®—MACD
        ema_12 = df['close'].ewm(span=12).mean()
        ema_26 = df['close'].ewm(span=26).mean()
        df['macd'] = ema_12 - ema_26
        
        # ... æ›´å¤šæŒ‡æ ‡
        
        return df
    
    def prepare_training_data(self, df):
        """å‡†å¤‡è®­ç»ƒæ•°æ®"""
        # 1. è®¡ç®—ç‰¹å¾
        df = self.build_features(df)
        
        # 2. æ ‡å‡†åŒ–
        features = df[feature_columns].values
        features = self.scaler.fit_transform(features)
        
        # 3. åˆ›å»ºæ—¶é—´çª—å£
        X, y = [], []
        for i in range(len(features) - self.window_size - 5):
            X.append(features[i:i+60])
            
            # è®¡ç®—æœªæ¥æ”¶ç›Šç‡
            future_return = (
                df['close'][i+60+5] - df['close'][i+60]
            ) / df['close'][i+60]
            y.append(future_return)
        
        return np.array(X), np.array(y), feature_columns
```

#### 2. ModelTrainerï¼ˆæ¨¡å‹è®­ç»ƒå™¨ï¼‰

```python
class ModelTrainer:
    def __init__(self, model, device='cpu', learning_rate=0.001):
        self.model = model
        self.device = device
        
        # æŸå¤±å‡½æ•°ï¼šå‡æ–¹è¯¯å·®
        self.criterion = nn.MSELoss()
        
        # ä¼˜åŒ–å™¨ï¼šAdam
        self.optimizer = optim.Adam(
            model.parameters(),
            lr=learning_rate
        )
        
        # å­¦ä¹ ç‡è°ƒåº¦å™¨
        self.scheduler = optim.lr_scheduler.ReduceLROnPlateau(
            self.optimizer,
            mode='min',
            factor=0.5,
            patience=5
        )
    
    def train_epoch(self, train_loader):
        """è®­ç»ƒä¸€ä¸ªepoch"""
        self.model.train()
        total_loss = 0
        
        for batch_X, batch_y in train_loader:
            # å‰å‘ä¼ æ’­
            predictions = self.model(batch_X)
            loss = self.criterion(predictions.squeeze(), batch_y)
            
            # åå‘ä¼ æ’­
            self.optimizer.zero_grad()
            loss.backward()
            
            # æ¢¯åº¦è£å‰ª
            torch.nn.utils.clip_grad_norm_(
                self.model.parameters(),
                max_norm=1.0
            )
            
            # æ›´æ–°æƒé‡
            self.optimizer.step()
            
            total_loss += loss.item()
        
        return total_loss / len(train_loader)
    
    def validate(self, val_loader):
        """éªŒè¯"""
        self.model.eval()
        total_loss = 0
        
        with torch.no_grad():
            for batch_X, batch_y in val_loader:
                predictions = self.model(batch_X)
                loss = self.criterion(predictions.squeeze(), batch_y)
                total_loss += loss.item()
        
        return total_loss / len(val_loader)
```

---

## å®æˆ˜æ¡ˆä¾‹

### æ¡ˆä¾‹1ï¼šé¢„æµ‹å¹³å®‰é“¶è¡Œï¼ˆ000001ï¼‰

```python
# 1. è®­ç»ƒæ¨¡å‹
python train.py --stock_code 000001 --collect_data

# è¾“å‡ºï¼š
# æ•°æ®åŠ è½½å®Œæˆ: 1456 æ¡è®°å½•
# ç‰¹å¾æ•°é‡: 36
# è®­ç»ƒæ•°æ®å‡†å¤‡å®Œæˆ: X shape=(1333, 60, 36)
# 
# Epoch [1/100] - Train Loss: 0.004760, Val Loss: 0.001660
# Epoch [2/100] - Train Loss: 0.003221, Val Loss: 0.001389
# ...
# Epoch [22/100] - Early stopping
# 
# æµ‹è¯•é›†è¯„ä¼°:
# - MSE: 0.000395
# - MAE: 0.015573 (1.56%)
# - æ–¹å‘å‡†ç¡®ç‡: 56.72%
```

### æ¡ˆä¾‹2ï¼šä½¿ç”¨APIè¿›è¡Œé¢„æµ‹

```python
# å¯åŠ¨APIæœåŠ¡
python -m uvicorn src.api.main:app --port 8000

# ä½¿ç”¨Pythonè°ƒç”¨
import requests

response = requests.post(
    'http://localhost:8000/api/predict',
    json={'stock_code': '000001', 'days': 5}
)

result = response.json()
print(result)
# {
#   "stock_code": "000001",
#   "prediction": 0.0234,  # é¢„æµ‹æœªæ¥5å¤©æ”¶ç›Šç‡2.34%
#   "direction": "ä¸Šæ¶¨"
# }
```

**ç±»æ¯”å‰ç«¯**ï¼š
```javascript
// å°±åƒè°ƒç”¨ä¸€ä¸ªAPI
async function predictStock(stockCode) {
  const response = await fetch('/api/predict', {
    method: 'POST',
    headers: { 'Content-Type': 'application/json' },
    body: JSON.stringify({
      stock_code: stockCode,
      days: 5
    })
  });
  
  const result = await response.json();
  
  if (result.prediction > 0) {
    console.log(`é¢„æµ‹ä¸Šæ¶¨ ${(result.prediction * 100).toFixed(2)}%`);
  } else {
    console.log(`é¢„æµ‹ä¸‹è·Œ ${(result.prediction * 100).toFixed(2)}%`);
  }
}
```

### æ¡ˆä¾‹3ï¼šç†è§£é¢„æµ‹ç»“æœ

```python
# é¢„æµ‹ç»“æœç¤ºä¾‹
prediction = 0.0234  # 2.34%

# è§£è¯»ï¼š
# 1. æ­£å€¼ï¼šé¢„æµ‹ä¸Šæ¶¨
# 2. è´Ÿå€¼ï¼šé¢„æµ‹ä¸‹è·Œ
# 3. ç»å¯¹å€¼å¤§å°ï¼šæ¶¨è·Œå¹…åº¦

# å®é™…åº”ç”¨ï¼š
current_price = 10.50  # å½“å‰ä»·æ ¼
predicted_price = current_price * (1 + prediction)
# predicted_price = 10.50 * 1.0234 = 10.75å…ƒ

print(f"å½“å‰ä»·æ ¼: {current_price}å…ƒ")
print(f"é¢„æµ‹ä»·æ ¼: {predicted_price:.2f}å…ƒ")
print(f"é¢„æµ‹æ¶¨å¹…: {prediction * 100:.2f}%")
```

---

## å¸¸è§é—®é¢˜è§£ç­”

### Q1: ä¸ºä»€ä¹ˆæ–¹å‘å‡†ç¡®ç‡åªæœ‰56%ï¼Ÿ

**A**: è¿™å·²ç»æ¯”éšæœºçŒœæµ‹ï¼ˆ50%ï¼‰å¥½äº†ï¼è‚¡ç¥¨é¢„æµ‹æœ¬èº«å°±å¾ˆéš¾ã€‚

**æ”¹è¿›æ–¹æ³•**ï¼š
1. å¢åŠ æ›´å¤šæ•°æ®
2. å°è¯•ä¸åŒçš„æ¨¡å‹ç»“æ„
3. æ·»åŠ æ›´å¤šç‰¹å¾
4. è°ƒæ•´è¶…å‚æ•°

### Q2: å¦‚ä½•åˆ¤æ–­æ¨¡å‹æ˜¯å¦è¿‡æ‹Ÿåˆï¼Ÿ

**A**: çœ‹è®­ç»ƒæŸå¤±å’ŒéªŒè¯æŸå¤±çš„å·®è·ã€‚

```
å¥½çš„æƒ…å†µï¼š
Train Loss: 0.002  Val Loss: 0.002  âœ“ å·®è·å°

è¿‡æ‹Ÿåˆï¼š
Train Loss: 0.001  Val Loss: 0.005  âœ— å·®è·å¤§
```

**è§£å†³æ–¹æ³•**ï¼š
- å¢åŠ Dropout
- å‡å°‘æ¨¡å‹å¤æ‚åº¦
- å¢åŠ è®­ç»ƒæ•°æ®
- Early Stopping

### Q3: å¦‚ä½•é€‰æ‹©è¶…å‚æ•°ï¼Ÿ

**å¸¸ç”¨è¶…å‚æ•°**ï¼š

```python
# LSTMå‚æ•°
hidden_size = 128      # éšè—å±‚å¤§å°ï¼š64/128/256
num_layers = 2         # LSTMå±‚æ•°ï¼š1/2/3
dropout = 0.2          # Dropoutç‡ï¼š0.1/0.2/0.3

# è®­ç»ƒå‚æ•°
batch_size = 32        # æ‰¹æ¬¡å¤§å°ï¼š16/32/64
learning_rate = 0.001  # å­¦ä¹ ç‡ï¼š0.0001/0.001/0.01
epochs = 100           # è®­ç»ƒè½®æ•°ï¼š50/100/200

# æ•°æ®å‚æ•°
window_size = 60       # æ—¶é—´çª—å£ï¼š30/60/90å¤©
prediction_horizon = 5 # é¢„æµ‹å¤©æ•°ï¼š1/5/10å¤©
```

**è°ƒå‚å»ºè®®**ï¼š
1. å…ˆç”¨é»˜è®¤å€¼
2. ä¸€æ¬¡åªæ”¹ä¸€ä¸ªå‚æ•°
3. è§‚å¯ŸéªŒè¯æŸå¤±çš„å˜åŒ–
4. è®°å½•æ¯æ¬¡å®éªŒçš„ç»“æœ

### Q4: æ¨¡å‹è®­ç»ƒéœ€è¦å¤šé•¿æ—¶é—´ï¼Ÿ

**å–å†³äº**ï¼š
- æ•°æ®é‡ï¼š1000æ¡ vs 10000æ¡
- æ¨¡å‹å¤§å°ï¼šç®€å• vs å¤æ‚
- ç¡¬ä»¶ï¼šCPU vs GPU
- Batch Sizeï¼šå¤§ vs å°

**å‚è€ƒæ—¶é—´**ï¼ˆCPUï¼‰ï¼š
```
æ•°æ®é‡1500æ¡ï¼Œ100è½®è®­ç»ƒï¼š
- ç®€å•æ¨¡å‹ï¼š2-3åˆ†é’Ÿ
- å¤æ‚æ¨¡å‹ï¼š5-10åˆ†é’Ÿ

ä½¿ç”¨GPUå¯ä»¥å¿«5-10å€
```

### Q5: å¦‚ä½•åœ¨å®é™…äº¤æ˜“ä¸­ä½¿ç”¨ï¼Ÿ

**âš ï¸ é‡è¦æç¤º**ï¼š
1. æœ¬ç³»ç»Ÿä»…ä¾›å­¦ä¹ ç ”ç©¶
2. ä¸è¦ç›´æ¥ç”¨äºå®ç›˜äº¤æ˜“
3. è‚¡å¸‚æœ‰é£é™©ï¼ŒæŠ•èµ„éœ€è°¨æ…

**å¦‚æœè¦å®é™…ä½¿ç”¨**ï¼š
1. éœ€è¦æ›´å¤šçš„å›æµ‹
2. éœ€è¦é£é™©ç®¡ç†ç­–ç•¥
3. éœ€è¦è€ƒè™‘äº¤æ˜“æˆæœ¬
4. éœ€è¦å®æ—¶æ•°æ®æº

---

## è¿›é˜¶å­¦ä¹ è·¯å¾„

### 1. æ·±å…¥ç†è§£æ·±åº¦å­¦ä¹ 

**æ¨èèµ„æº**ï¼š
- å´æ©è¾¾ã€Šæ·±åº¦å­¦ä¹ ä¸“é¡¹è¯¾ç¨‹ã€‹
- æå®æ¯…ã€Šæœºå™¨å­¦ä¹ ã€‹
- ã€ŠåŠ¨æ‰‹å­¦æ·±åº¦å­¦ä¹ ã€‹

### 2. æ”¹è¿›æ¨¡å‹

**å¯ä»¥å°è¯•**ï¼š
- GRUæ¨¡å‹ï¼ˆLSTMçš„ç®€åŒ–ç‰ˆï¼‰
- Transformeræ¨¡å‹ï¼ˆæ³¨æ„åŠ›æœºåˆ¶ï¼‰
- é›†æˆå­¦ä¹ ï¼ˆå¤šä¸ªæ¨¡å‹æŠ•ç¥¨ï¼‰

### 3. æ·»åŠ æ›´å¤šç‰¹å¾

```python
# å¸‚åœºæƒ…ç»ªç‰¹å¾
- æ–°é—»æƒ…æ„Ÿåˆ†æ
- ç¤¾äº¤åª’ä½“çƒ­åº¦
- æœºæ„æŒä»“å˜åŒ–

# å®è§‚ç»æµç‰¹å¾
- åˆ©ç‡
- æ±‡ç‡
- GDPå¢é•¿ç‡

# è¡Œä¸šç‰¹å¾
- è¡Œä¸šæŒ‡æ•°
- åŒè¡Œä¸šè‚¡ç¥¨è¡¨ç°
```

### 4. å®ç°å›æµ‹ç³»ç»Ÿ

```python
class Backtester:
    def __init__(self, initial_capital=100000):
        self.capital = initial_capital
        self.positions = {}
    
    def backtest(self, predictions, prices):
        for i, pred in enumerate(predictions):
            if pred > 0.02:  # é¢„æµ‹ä¸Šæ¶¨>2%
                self.buy(prices[i])
            elif pred < -0.01:  # é¢„æµ‹ä¸‹è·Œ>1%
                self.sell(prices[i])
        
        return self.calculate_returns()
```

---

## æ€»ç»“

### æ ¸å¿ƒè¦ç‚¹

1. **æ•°æ®æ˜¯åŸºç¡€**
   - é«˜è´¨é‡çš„æ•°æ® > å¤æ‚çš„æ¨¡å‹
   - ç‰¹å¾å·¥ç¨‹å¾ˆé‡è¦

2. **æ¨¡å‹æ˜¯å·¥å…·**
   - LSTMé€‚åˆæ—¶é—´åºåˆ—
   - ä¸è¦è¿‡åº¦å¤æ‚åŒ–

3. **è®­ç»ƒæ˜¯å…³é”®**
   - é˜²æ­¢è¿‡æ‹Ÿåˆ
   - åˆç†çš„è¶…å‚æ•°
   - å……åˆ†çš„éªŒè¯

4. **è¯„ä¼°è¦å…¨é¢**
   - ä¸åªçœ‹å‡†ç¡®ç‡
   - è¦çœ‹å®é™…æ”¶ç›Š
   - è¦è€ƒè™‘é£é™©

### ç±»æ¯”æ€»ç»“

```javascript
// æ·±åº¦å­¦ä¹  = æ™ºèƒ½çš„å‡½æ•°
function traditionalPredict(data) {
  // äººå·¥å†™è§„åˆ™
  if (data.ma5 > data.ma10) return 'buy';
  return 'sell';
}

function deepLearningPredict(data) {
  // æ¨¡å‹è‡ªå·±å­¦ä¹ è§„åˆ™
  const model = trainedModel;
  return model.predict(data);
}
```

### ä¸‹ä¸€æ­¥è¡ŒåŠ¨

1. âœ… è¿è¡Œå¿«é€Ÿç¤ºä¾‹
2. âœ… è®­ç»ƒç¬¬ä¸€ä¸ªæ¨¡å‹
3. âœ… ç†è§£è®­ç»ƒè¿‡ç¨‹
4. â¬œ å°è¯•è°ƒæ•´å‚æ•°
5. â¬œ æ·»åŠ æ–°çš„ç‰¹å¾
6. â¬œ å®ç°å›æµ‹ç³»ç»Ÿ

---

## é™„å½•

### A. å¸¸ç”¨æœ¯è¯­å¯¹ç…§è¡¨

| æœ¯è¯­ | è‹±æ–‡ | è§£é‡Š | ç±»æ¯” |
|------|------|------|------|
| ç‰¹å¾ | Feature | ç”¨äºé¢„æµ‹çš„æ•°æ® | å‰ç«¯çš„props |
| æ ‡ç­¾ | Label | è¦é¢„æµ‹çš„ç›®æ ‡ | å‰ç«¯çš„state |
| è®­ç»ƒ | Training | è®©æ¨¡å‹å­¦ä¹  | è°ƒè¯•ä»£ç  |
| æ¨ç† | Inference | ä½¿ç”¨æ¨¡å‹é¢„æµ‹ | è¿è¡Œä»£ç  |
| è¿‡æ‹Ÿåˆ | Overfitting | è®°ä½è®­ç»ƒæ•°æ®ï¼Œä¸èƒ½æ³›åŒ– | å†™æ­»æ•°æ® |
| æ¬ æ‹Ÿåˆ | Underfitting | æ¨¡å‹å¤ªç®€å•ï¼Œå­¦ä¸ä¼š | é€»è¾‘å¤ªç®€å• |
| æ¢¯åº¦ | Gradient | æŸå¤±å‡½æ•°çš„å¯¼æ•° | ä¼˜åŒ–æ–¹å‘ |
| åå‘ä¼ æ’­ | Backpropagation | è®¡ç®—æ¢¯åº¦çš„ç®—æ³• | é”™è¯¯è¿½è¸ª |

### B. æ•°å­¦å…¬å¼é€ŸæŸ¥

```python
# 1. æ”¶ç›Šç‡
return = (future_price - current_price) / current_price 2. ç§»åŠ¨å¹³

#å‡
MA_n = (P1 + P2 + ... + Pn) / n

# 3. å‡æ–¹è¯¯å·®
MSE = Î£(prediction - actual)Â² / n

# 4. Sigmoidå‡½æ•°
sigmoid(x) = 1 / (1 + e^(-x))

# 5. ReLUå‡½æ•°
relu(x) = max(0, x)
```

### C. ä»£ç ç‰‡æ®µé€ŸæŸ¥

```python
# åŠ è½½æ¨¡å‹
model = LSTMModel(input_size=36)
model.load_state_dict(torch.load('model.pth'))

# é¢„æµ‹
model.eval()
with torch.no_grad():
    prediction = model(X)

# ä¿å­˜æ¨¡å‹
torch.save(model.state_dict(), 'model.pth')

# åŠ è½½Scaler
with open('scaler.pkl', 'rb') as f:
    scaler = pickle.load(f)
```

---

**ç¥æ‚¨å­¦ä¹ æ„‰å¿«ï¼** ğŸš€

å¦‚æœ‰ç–‘é—®ï¼Œæ¬¢è¿éšæ—¶æé—®ï¼
